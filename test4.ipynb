{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "799ddff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_endpoints import api_teams\n",
    "from api_endpoints import api_team_roasters\n",
    "from api_endpoints import api_season_details\n",
    "from api_endpoints import api_player_profile\n",
    "\n",
    "from util import obj_to_file\n",
    "from util import file_to_obj\n",
    "from util import df_to_file\n",
    "from util import file_to_df\n",
    "\n",
    "import time\n",
    "\n",
    "from util import to_mysql_timestamp\n",
    "from api_endpoints import api_ranking\n",
    "\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os, time, random\n",
    "\n",
    "DB_NAME = \"ncaafb_db\"\n",
    "SCHEMA_FILE = \"schema.sql\"\n",
    "HOST_ID = \"localhost\"\n",
    "USER_NAME = \"root\"\n",
    "USER_PASSWORD = \"root\"\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "\n",
    "def _get(d, keys, default=None):\n",
    "    \"\"\"Safe nested dict getter: _get(d, ['a','b']) -> d['a']['b'] or default.\"\"\"\n",
    "    cur = d\n",
    "    for k in keys:\n",
    "        if not isinstance(cur, dict) or k not in cur:\n",
    "            return default\n",
    "        cur = cur[k]\n",
    "    return cur\n",
    "\n",
    "\n",
    "def get_all_just_teams_id_list():\n",
    "    print(\"fetching all teams id's..\")\n",
    "    teams = api_teams()\n",
    "    teams_id = [team[\"id\"] for team in teams[\"teams\"]]\n",
    "    obj_to_file(teams_id, \"./db_csv/teams_id_list\")\n",
    "    return teams_id\n",
    "\n",
    "\n",
    "def get_all_seasons_list():\n",
    "    print(\"fetching all season's detail..\")\n",
    "    season_details = api_season_details()\n",
    "    season_list = season_details[\"seasons\"]\n",
    "    obj_to_file(season_list, \"./db_csv/seasons_list\")\n",
    "    return season_list\n",
    "\n",
    "\n",
    "def db_populate_seasons(season_list, engine):\n",
    "    seasons_df = pd.DataFrame(\n",
    "        columns=[\"season_id\", \"year\", \"start_date\", \"end_date\", \"status\", \"type_code\"]\n",
    "    )\n",
    "    for season in season_list:\n",
    "        season_dict = {\n",
    "            \"season_id\": _get(season, [\"id\"]),\n",
    "            \"year\": _get(season, [\"year\"]),\n",
    "            \"start_date\": _get(season, [\"start_date\"]),\n",
    "            \"end_date\": _get(season, [\"end_date\"]),\n",
    "            \"status\": _get(season, [\"status\"]),\n",
    "            \"type_code\": _get(season, [\"type\", \"code\"]),\n",
    "        }\n",
    "\n",
    "        if (\n",
    "            season_dict[\"season_id\"] is not None\n",
    "            and season_dict[\"season_id\"] not in seasons_df[\"season_id\"].values\n",
    "        ):\n",
    "            seasons_df.loc[len(seasons_df)] = season_dict\n",
    "\n",
    "    seasons_df.to_sql(\"SEASONS\", engine, index=False, if_exists=\"append\")\n",
    "    df_to_file(seasons_df, \"./db_csv/SEASONS.csv\")\n",
    "    print(\"db updated: seasons.\")\n",
    "\n",
    "\n",
    "def get_all_teams_roaster_list(teams_id):\n",
    "    def _fetch_roaster(tid, max_retries=1, base_backoff=1.0):\n",
    "        backoff = base_backoff\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            try:\n",
    "                res = api_team_roasters(tid)\n",
    "            except Exception as e:\n",
    "                msg = str(e)\n",
    "                # treat typical rate-limit errors as retryable\n",
    "                if \"Too Many Requests\" in msg or \"429\" in msg:\n",
    "                    print(f\"Too Many Requests: {tid}\")\n",
    "                    wait = backoff + random.uniform(0, 0.5)\n",
    "                    time.sleep(wait)\n",
    "                    backoff *= 2\n",
    "                    continue\n",
    "                return {\"id\": tid, \"_error\": msg}\n",
    "\n",
    "            # api wrapper may return a dict with a 'message' or '_error'\n",
    "            if isinstance(res, dict) and (\n",
    "                res.get(\"message\") == \"Too Many Requests\"\n",
    "                or \"Too Many Requests\" in str(res.get(\"_error\", \"\"))\n",
    "            ):\n",
    "                # if the API returned Retry-After in headers, use that (needs wrapper change to expose headers)\n",
    "                wait = backoff + random.uniform(0, 0.5)\n",
    "                time.sleep(wait)\n",
    "                backoff *= 2\n",
    "                continue\n",
    "\n",
    "            return res\n",
    "\n",
    "        return {\"id\": tid, \"_error\": \"TooManyRequests_after_retries\"}\n",
    "\n",
    "    # lower concurrency to avoid bursts\n",
    "    max_workers = min(10, (os.cpu_count() or 1) * 2, len(teams_id))\n",
    "    roasters_list = []\n",
    "    print(\"fetching all team's roaster detail..\")\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futures = [ex.submit(_fetch_roaster, tid) for tid in teams_id]\n",
    "        for i, fut in enumerate(as_completed(futures), 1):\n",
    "            roasters_list.append(fut.result())\n",
    "            if i % 50 == 0 or i == len(teams_id):\n",
    "                print(f\"Fetched {i}/{len(teams_id)}\")\n",
    "\n",
    "    obj_to_file(roasters_list, \"./db_csv/roasters_list\")\n",
    "    return roasters_list\n",
    "\n",
    "\n",
    "def db_populate_venues_divisons_confs_teams_coaches_players(roasters_list, engine):\n",
    "    venue_df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"venue_id\",\n",
    "            \"name\",\n",
    "            \"city\",\n",
    "            \"state\",\n",
    "            \"country\",\n",
    "            \"zip\",\n",
    "            \"address\",\n",
    "            \"capacity\",\n",
    "            \"surface\",\n",
    "            \"roof_type\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "        ]\n",
    "    )\n",
    "    conferene_df = pd.DataFrame(columns=[\"conference_id\", \"name\", \"alias\"])\n",
    "    divison_df = pd.DataFrame(columns=[\"division_id\", \"name\", \"alias\"])\n",
    "    teams_df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"team_id\",\n",
    "            \"market\",\n",
    "            \"name\",\n",
    "            \"alias\",\n",
    "            \"founded\",\n",
    "            \"mascot\",\n",
    "            \"fight_song\",\n",
    "            \"championships_won\",\n",
    "            \"conference_id\",\n",
    "            \"division_id\",\n",
    "            \"venue_id\",\n",
    "        ]\n",
    "    )\n",
    "    players_df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"player_id\",\n",
    "            \"first_name\",\n",
    "            \"last_name\",\n",
    "            \"abbr_name\",\n",
    "            \"birth_place\",\n",
    "            \"position\",\n",
    "            \"height\",\n",
    "            \"weight\",\n",
    "            \"status\",\n",
    "            \"eligibility\",\n",
    "            \"team_id\",\n",
    "        ]\n",
    "    )\n",
    "    coaches_df = pd.DataFrame(columns=[\"coach_id\", \"full_name\", \"position\", \"team_id\"])\n",
    "\n",
    "    for roaster in roasters_list:\n",
    "        print(roaster)\n",
    "        if not isinstance(roaster, dict) or \"id\" not in roaster:\n",
    "            continue\n",
    "\n",
    "        venue_dict = {\n",
    "            \"venue_id\": _get(roaster, [\"venue\", \"id\"]),\n",
    "            \"name\": _get(roaster, [\"venue\", \"name\"]),\n",
    "            \"city\": _get(roaster, [\"venue\", \"city\"]),\n",
    "            \"state\": _get(roaster, [\"venue\", \"state\"]),\n",
    "            \"country\": _get(roaster, [\"venue\", \"country\"]),\n",
    "            \"zip\": _get(roaster, [\"venue\", \"zip\"]),\n",
    "            \"address\": _get(roaster, [\"venue\", \"address\"]),\n",
    "            \"capacity\": _get(roaster, [\"venue\", \"capacity\"]),\n",
    "            \"surface\": _get(roaster, [\"venue\", \"surface\"]),\n",
    "            \"roof_type\": _get(roaster, [\"venue\", \"roof_type\"]),\n",
    "            \"latitude\": _get(roaster, [\"venue\", \"location\", \"lat\"]),\n",
    "            \"longitude\": _get(roaster, [\"venue\", \"location\", \"lng\"]),\n",
    "        }\n",
    "\n",
    "        conference_dict = {\n",
    "            \"conference_id\": _get(roaster, [\"conference\", \"id\"]),\n",
    "            \"name\": _get(roaster, [\"conference\", \"name\"]),\n",
    "            \"alias\": _get(roaster, [\"conference\", \"alias\"]),\n",
    "        }\n",
    "\n",
    "        division_dict = {\n",
    "            \"division_id\": _get(roaster, [\"division\", \"id\"]),\n",
    "            \"name\": _get(roaster, [\"division\", \"name\"]),\n",
    "            \"alias\": _get(roaster, [\"division\", \"alias\"]),\n",
    "        }\n",
    "\n",
    "        teams_dict = {\n",
    "            \"team_id\": _get(roaster, [\"id\"]),\n",
    "            \"market\": _get(roaster, [\"market\"]),\n",
    "            \"name\": _get(roaster, [\"name\"]),\n",
    "            \"alias\": _get(roaster, [\"alias\"]),\n",
    "            \"founded\": _get(roaster, [\"founded\"]),\n",
    "            \"mascot\": _get(roaster, [\"mascot\"]),\n",
    "            \"fight_song\": _get(roaster, [\"fight_song\"]),\n",
    "            \"championships_won\": _get(roaster, [\"championships_won\"]),\n",
    "            \"conference_id\": _get(roaster, [\"conference\", \"id\"]),\n",
    "            \"division_id\": _get(roaster, [\"division\", \"id\"]),\n",
    "            \"venue_id\": _get(roaster, [\"venue\", \"id\"]),\n",
    "        }\n",
    "\n",
    "        # Replacements to avoid FutureWarning:\n",
    "        if (\n",
    "            venue_dict[\"venue_id\"] is not None\n",
    "            and venue_dict[\"venue_id\"] not in venue_df[\"venue_id\"].values\n",
    "        ):\n",
    "            venue_df = pd.concat(\n",
    "                [venue_df, pd.DataFrame([venue_dict])], ignore_index=True\n",
    "            )\n",
    "\n",
    "        if (\n",
    "            conference_dict[\"conference_id\"] is not None\n",
    "            and conference_dict[\"conference_id\"]\n",
    "            not in conferene_df[\"conference_id\"].values\n",
    "        ):\n",
    "            conferene_df = pd.concat(\n",
    "                [conferene_df, pd.DataFrame([conference_dict])], ignore_index=True\n",
    "            )\n",
    "\n",
    "        if (\n",
    "            division_dict[\"division_id\"] is not None\n",
    "            and division_dict[\"division_id\"] not in divison_df[\"division_id\"].values\n",
    "        ):\n",
    "            divison_df = pd.concat(\n",
    "                [divison_df, pd.DataFrame([division_dict])], ignore_index=True\n",
    "            )\n",
    "\n",
    "        if (\n",
    "            teams_dict[\"team_id\"] is not None\n",
    "            and teams_dict[\"team_id\"] not in teams_df[\"team_id\"].values\n",
    "        ):\n",
    "            teams_df = pd.concat(\n",
    "                [teams_df, pd.DataFrame([teams_dict])], ignore_index=True\n",
    "            )\n",
    "\n",
    "        print(\"v|d|c|t done\")\n",
    "\n",
    "        # Coaches\n",
    "        for coach in roaster.get(\"coaches\", []) or []:\n",
    "            c = {\n",
    "                \"coach_id\": _get(coach, [\"id\"]),\n",
    "                \"full_name\": _get(coach, [\"full_name\"]),\n",
    "                \"position\": _get(coach, [\"position\"]),\n",
    "                \"team_id\": teams_dict[\"team_id\"],\n",
    "            }\n",
    "            if (\n",
    "                c[\"coach_id\"] is not None\n",
    "                and c[\"coach_id\"] not in coaches_df[\"coach_id\"].values\n",
    "            ):\n",
    "                coaches_df = pd.concat(\n",
    "                    [coaches_df, pd.DataFrame([c])], ignore_index=True\n",
    "                )\n",
    "            print(\"c done\")\n",
    "\n",
    "        # Players\n",
    "        for player in roaster.get(\"players\", []) or []:\n",
    "            p = {\n",
    "                \"player_id\": _get(player, [\"id\"]),\n",
    "                \"first_name\": _get(player, [\"first_name\"]),\n",
    "                \"last_name\": _get(player, [\"last_name\"]),\n",
    "                \"abbr_name\": _get(player, [\"abbr_name\"]),\n",
    "                \"birth_place\": _get(player, [\"birth_place\"]),\n",
    "                \"position\": _get(player, [\"position\"]),\n",
    "                \"height\": _get(player, [\"height\"]),\n",
    "                \"weight\": _get(player, [\"weight\"]),\n",
    "                \"status\": _get(player, [\"status\"]),\n",
    "                \"eligibility\": _get(player, [\"eligibility\"]),\n",
    "                \"team_id\": teams_dict[\"team_id\"],\n",
    "            }\n",
    "            if (\n",
    "                p[\"player_id\"] is not None\n",
    "                and p[\"player_id\"] not in players_df[\"player_id\"].values\n",
    "            ):\n",
    "                players_df = pd.concat(\n",
    "                    [players_df, pd.DataFrame([p])], ignore_index=True\n",
    "                )\n",
    "            print(\" pdone\")\n",
    "\n",
    "    print(\"uploading to sql\")\n",
    "\n",
    "    tables = [\n",
    "        (conferene_df, \"CONFERENCES\"),\n",
    "        (venue_df, \"VENUES\"),\n",
    "        (divison_df, \"DIVISIONS\"),\n",
    "        (teams_df, \"TEAMS\"),\n",
    "        (players_df, \"PLAYERS\"),\n",
    "        (coaches_df, \"COACHES\"),\n",
    "    ]\n",
    "\n",
    "    for df, table_name in tables:\n",
    "        csv_path = f\"./db_csv/{table_name}.csv\"\n",
    "        try:\n",
    "            df.to_csv(csv_path, index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to write CSV {csv_path}: {e}\")\n",
    "        try:\n",
    "            df.to_sql(table_name, engine, index=False, if_exists=\"append\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to write SQL table {table_name}: {e}\")\n",
    "\n",
    "    print(\"db updated: \" + \", \".join([t for _, t in tables]))\n",
    "\n",
    "    # preserve previous behavior of saving player ids and returning them\n",
    "    obj_to_file(players_df[\"player_id\"].values, \"./db_csv/players_ids\")\n",
    "    print(\"file player_id saved\")\n",
    "    # return players_df[\"player_id\"].values\n",
    "\n",
    "\n",
    "def get_player_profiles_list(players_id):\n",
    "    def _fetch_player_profile(pid, max_retries=5):\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                return api_player_profile(pid)\n",
    "            except Exception as e:\n",
    "                msg = str(e)\n",
    "                # backoff on rate limit-ish errors\n",
    "                if \"Too Many Requests\" in msg or \"429\" in msg:\n",
    "                    time.sleep((2**attempt) * 0.1 + 0.1)\n",
    "                    continue\n",
    "                return {\"player_id\": pid, \"_error\": msg}\n",
    "        return {\"player_id\": pid, \"_error\": \"TooManyRequests_after_retries\"}\n",
    "\n",
    "    max_workers = min(50, (os.cpu_count() or 1) * 5, len(players_id))\n",
    "    playerprof_list = []\n",
    "    print(\"fetching all player's stats..\")\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futures = {ex.submit(_fetch_player_profile, pid): pid for pid in players_id}\n",
    "        for i, fut in enumerate(as_completed(futures), 1):\n",
    "            playerprof_list.append(fut.result())\n",
    "            if i % 100 == 0 or i == len(players_id):\n",
    "                print(f\"Fetched {i}/{len(players_id)}\")\n",
    "\n",
    "    obj_to_file(playerprof_list, \"./db_csv/players_profiles_list\")\n",
    "    return playerprof_list\n",
    "\n",
    "\n",
    "def db_populate_players_statistics(playerprof_list, engine):\n",
    "    playerstat_df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"player_id\",\n",
    "            \"team_id\",\n",
    "            \"season_id\",\n",
    "            \"games_played\",\n",
    "            \"games_started\",\n",
    "            \"rushing_yards\",\n",
    "            \"rushing_touchdowns\",\n",
    "            \"receiving_yards\",\n",
    "            \"receiving_touchdowns\",\n",
    "            \"kick_return_yards\",\n",
    "            \"fumbles\",\n",
    "        ]\n",
    "    )\n",
    "    for player in playerprof_list:\n",
    "        playerstat_dict = {key: None for key in playerstat_df.columns}\n",
    "        playerstat_dict[\"player_id\"] = _get(player, [\"id\"])\n",
    "        playerstat_dict[\"team_id\"] = _get(player, [\"team\", \"id\"])\n",
    "        if _get(player, [\"seasons\"]) in [None, []]:\n",
    "            playerstat_df.loc[len(playerstat_df)] = playerstat_dict\n",
    "            continue\n",
    "\n",
    "        for season in player[\"seasons\"]:\n",
    "            playerstat_dict[\"season_id\"] = _get(season, [\"id\"])\n",
    "            if _get(season, [\"teams\"]) in [None, []]:\n",
    "                playerstat_df.loc[len(playerstat_df)] = playerstat_dict\n",
    "                continue\n",
    "\n",
    "            for team in season[\"teams\"]:\n",
    "                if (\n",
    "                    playerstat_dict[\"team_id\"] is not None\n",
    "                    and _get(team, [\"id\"]) == playerstat_dict[\"team_id\"]\n",
    "                ):\n",
    "                    playerstat_dict[\"team_id\"] = _get(team, [\"id\"])\n",
    "                    playerstat_dict[\"games_played\"] = _get(\n",
    "                        team, [\"statistics\", \"games_played\"]\n",
    "                    )\n",
    "                    playerstat_dict[\"games_started\"] = _get(\n",
    "                        team, [\"statistics\", \"games_started\"]\n",
    "                    )\n",
    "                    playerstat_dict[\"rushing_yards\"] = _get(\n",
    "                        team, [\"statistics\", \"rushing\", \"yards\"]\n",
    "                    )\n",
    "                    playerstat_dict[\"rushing_touchdowns\"] = _get(\n",
    "                        team, [\"statistics\", \"rushing\", \"touchdowns\"]\n",
    "                    )\n",
    "                    playerstat_dict[\"receiving_yards\"] = _get(\n",
    "                        team, [\"statistics\", \"receiving\", \"yards\"]\n",
    "                    )\n",
    "                    playerstat_dict[\"receiving_touchdowns\"] = _get(\n",
    "                        team, [\"statistics\", \"receiving\", \"touchdowns\"]\n",
    "                    )\n",
    "                    playerstat_dict[\"kick_return_yards\"] = _get(\n",
    "                        team, [\"statistics\", \"kick_returns\", \"yards\"]\n",
    "                    )\n",
    "                    playerstat_dict[\"fumbles\"] = _get(\n",
    "                        team, [\"statistics\", \"fumbles\", \"fumbles\"]\n",
    "                    )\n",
    "\n",
    "                    playerstat_df.loc[len(playerstat_df)] = playerstat_dict\n",
    "\n",
    "        df_to_file(playerstat_df, \"./db_csv/PLAYER_STATISTICS.csv\")\n",
    "        playerstat_df.to_sql(\n",
    "            \"PLAYER_STATISTICS\", engine, index=False, if_exists=\"append\"\n",
    "        )\n",
    "\n",
    "    print(\"db updated: player_statistics.\")\n",
    "\n",
    "def get_current_week_rankings():\n",
    "    return [api_ranking()]\n",
    "\n",
    "\n",
    "def db_populate_rankings(week_rankings, engine):\n",
    "    rank_curr_week_df = pd.DataFrame(columns=[\"ranking_id\", \n",
    "                                             \"poll_id\", \n",
    "                                             \"poll_name\",\n",
    "                                             \"season_id\",\n",
    "                                             \"week\",\n",
    "                                             \"effective_time\",\n",
    "                                             \"team_id\",\n",
    "                                             \"rank_position\",\n",
    "                                             \"prev_rank\",\n",
    "                                             \"points\",\n",
    "                                             \"fp_votes\",\n",
    "                                             \"wins\",\n",
    "                                             \"losses\",\n",
    "                                             \"ties\"])\n",
    "    # 754e4990-efc7-11ef-bb2a-5d2d22b9215e\n",
    "    rank_dict = {key:None for key in rank_curr_week_df.columns}\n",
    "    rank_dict[\"season_id\"] = \"754e4990-efc7-11ef-bb2a-5d2d22b9215e\"\n",
    "\n",
    "    for week_rank in week_rankings:\n",
    "        for team_rank in _get(week_rank, [\"rankings\"]):\n",
    "            rank_dict[\"poll_id\"] = _get(week_rank, [\"poll\", \"id\"])\n",
    "            rank_dict[\"poll_name\"] = _get(week_rank, [\"poll\", \"name\"])\n",
    "            rank_dict[\"week\"] = _get(week_rank, [\"week\"])\n",
    "            rank_dict[\"effective_time\"] = to_mysql_timestamp(_get(week_rank, [\"effective_time\"]))\n",
    "            rank_dict[\"team_id\"] = _get(team_rank, [\"id\"])\n",
    "            rank_dict[\"rank_position\"] = _get(team_rank, [\"rank\"])\n",
    "            rank_dict[\"prev_rank\"] = _get(team_rank, [\"prev_rank\"])\n",
    "            rank_dict[\"points\"] = _get(team_rank, [\"points\"])\n",
    "            rank_dict[\"fp_votes\"] = _get(team_rank, [\"fp_votes\"])\n",
    "            rank_dict[\"wins\"] = _get(team_rank, [\"wins\"])\n",
    "            rank_dict[\"losses\"] = _get(team_rank, [\"losses\"])\n",
    "            rank_dict[\"ties\"] = _get(team_rank, [\"ties\"])\n",
    "            rank_curr_week_df.loc[len(rank_curr_week_df)] = rank_dict\n",
    "    \n",
    "    df_to_file(rank_curr_week_df, \"./db_csv/RANKINGS.csv\")\n",
    "    print(\"RANKINGS.csv file saved\")\n",
    "    rank_curr_week_df.to_sql(\"RANKINGS\", engine, index=False, if_exists=\"append\")\n",
    "    print(\"db updated: rankings\")\n",
    "\n",
    "\n",
    "\n",
    "def _apply_schema(engine_db):\n",
    "    \"\"\"Apply schema only if not already applied.\"\"\"\n",
    "    with engine_db.connect() as conn:\n",
    "        # Check if schema version table exists\n",
    "        result = conn.execute(\n",
    "            text(\"\"\"\n",
    "            SELECT COUNT(*)\n",
    "            FROM information_schema.tables\n",
    "            WHERE table_schema = :db\n",
    "              AND table_name = 'schema_version'\n",
    "        \"\"\"),\n",
    "            {\"db\": DB_NAME},\n",
    "        ).scalar()\n",
    "\n",
    "        if result == 1:\n",
    "            print(\"Schema already applied â€” skipping.\")\n",
    "            return\n",
    "\n",
    "    print(\n",
    "        f\"Applying schema to {DB_NAME}\",\n",
    "        f\"Loading schema file from ./{SCHEMA_FILE}\",\n",
    "        sep=\"\\n\",\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with open(SCHEMA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            sql_content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Schema file '{SCHEMA_FILE}' not found.\")\n",
    "        return\n",
    "\n",
    "    # Split into SQL statements\n",
    "    statements = [stmt.strip() for stmt in sql_content.split(\";\") if stmt.strip()]\n",
    "\n",
    "    with engine_db.connect() as conn:\n",
    "        for stmt in statements:\n",
    "            try:\n",
    "                conn.execute(text(stmt))\n",
    "            except SQLAlchemyError as e:\n",
    "                print(f\"Error executing statement:\\n{stmt}\\n{e}\")\n",
    "\n",
    "        # Mark schema as applied\n",
    "        conn.execute(\n",
    "            text(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS schema_version (\n",
    "                id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "                applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        \"\"\")\n",
    "        )\n",
    "\n",
    "        conn.execute(text(\"INSERT INTO schema_version () VALUES ()\"))\n",
    "\n",
    "    print(\"Schema applied successfully.\")\n",
    "\n",
    "\n",
    "def ensure_database():\n",
    "    \"\"\"Ensure the database exists and return an engine bound to it.\"\"\"\n",
    "    server_url = f\"mysql+mysqlconnector://{USER_NAME}:{USER_PASSWORD}@{HOST_ID}\"\n",
    "\n",
    "    server_engine = create_engine(server_url)\n",
    "\n",
    "    with server_engine.connect() as conn:\n",
    "        conn.execute(\n",
    "            text(\n",
    "                f\"CREATE DATABASE IF NOT EXISTS `{DB_NAME}` \"\n",
    "                \"CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Now return engine bound to the database\n",
    "    engine_db = create_engine(server_url + f\"/{DB_NAME}\")\n",
    "    return engine_db\n",
    "\n",
    "\n",
    "def main():\n",
    "    # create sql engine with creditianls applied and schema applied\n",
    "    engine = ensure_database()\n",
    "    _apply_schema(engine)\n",
    "\n",
    "    # get all team's ids & save it to file\n",
    "    get_all_just_teams_id_list()\n",
    "    time.sleep(5)\n",
    "    # get all seasons detail save it to file\n",
    "    get_all_seasons_list()\n",
    "\n",
    "    # load seaons details from file and upload to database\n",
    "    seasons_list = file_to_obj(\"./db_csv/seasons_list\")\n",
    "    db_populate_seasons(seasons_list, engine)\n",
    "\n",
    "    # load teams's ids from file and get all team's roaster details\n",
    "    teams_id = file_to_obj(\"./db_csv/teams_id_list\")\n",
    "    get_all_teams_roaster_list(teams_id)\n",
    "\n",
    "    # load all teams roasters from file and upload to database\n",
    "    roasters_list = file_to_obj(\"./db_csv/roasters_list\")\n",
    "    db_populate_venues_divisons_confs_teams_coaches_players(roasters_list, engine)\n",
    "\n",
    "    # load player's ids from file and get player stats\n",
    "    players_ids = file_to_obj(\"./db_csv/players_ids\")\n",
    "    get_player_profiles_list(players_ids)\n",
    "\n",
    "    # load playear stats from file and upload to database\n",
    "    players_stats = file_to_obj(\"./db_csv/players_profiles_list\")\n",
    "    db_populate_players_statistics(players_stats, engine)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "\n",
    "# def ensure_database_and_schema():\n",
    "#     \"\"\"Ensure database exists and schema is applied. Executes schema.sql if necessary.\"\"\"\n",
    "#     # Connect to server (no DB)\n",
    "#     engine = get_engine(None)\n",
    "#     with engine.connect() as conn:\n",
    "#         # create database if not exists\n",
    "#         conn.execute(text(f\"CREATE DATABASE IF NOT EXISTS `{DB_NAME}` CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;\"))\n",
    "#         conn.commit()\n",
    "\n",
    "#     # Connect to target DB and check if tables exist; if not, run schema\n",
    "#     engine_db = get_engine(DB_NAME)\n",
    "#     with engine_db.connect() as conn:\n",
    "#         # check for any table\n",
    "#         result = conn.execute(text(\"SELECT COUNT(*) as c FROM information_schema.tables WHERE table_schema = :schema\"), {\"schema\": DB_NAME})\n",
    "#         count = result.mappings().first()[\"c\"]\n",
    "#         if count == 0:\n",
    "#             # load schema file and execute\n",
    "#             if not os.path.exists(SCHEMA_PATH):\n",
    "#                 st.error(f\"Schema file not found at {SCHEMA_PATH}\")\n",
    "#                 return False\n",
    "#             with open(SCHEMA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "#                 schema_sql = f.read()\n",
    "#             # naive split by ; to execute statements safely; preserve DELIMITER statements\n",
    "#             statements = [s.strip() for s in schema_sql.split(';') if s.strip()]\n",
    "#             for stmt in statements:\n",
    "#                 try:\n",
    "#                     conn.execute(text(stmt))\n",
    "#                 except Exception as e:\n",
    "#                     # ignore statements that cannot run alone (e.g., DELIMITER-related or comments)\n",
    "#                     print(\"Schema execution error for statement chunk:\", e)\n",
    "#             conn.commit()\n",
    "#             st.info(\"Database schema initialized from schema.sql\")\n",
    "#         else:\n",
    "#             st.info(\"Database already contains tables - skipping schema initialization\")\n",
    "#     return True\n",
    "\n",
    "# Ensure DB and schema\n",
    "# with st.spinner(\"Checking database and schema...\"):\n",
    "#     ok = ensure_database_and_schema()\n",
    "#     if not ok:\n",
    "#         st.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1d2793",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = ensure_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01c364f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings = get_current_week_rankings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3eb6a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANKINGS.csv file saved\n",
      "db updated: rankings\n"
     ]
    }
   ],
   "source": [
    "db_populate_rankings(rankings, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4285ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-02T23:36:00+00:00\n",
      "2025-12-02 23:36:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def to_mysql_timestamp(param_str):\n",
    "    # Extract the value between quotes\n",
    "    value = param_str.strip().strip('\"')\n",
    "    \n",
    "    # Parse ISO 8601 datetime with timezone\n",
    "    dt = datetime.fromisoformat(value)\n",
    "    \n",
    "    # Convert to MySQL timestamp (UTC or local, depending on your needs)\n",
    "    return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Example\n",
    "s = \"2025-12-02T23:36:00+00:00\"\n",
    "print(to_mysql_timestamp(s))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486951f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sportradar-dashboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
